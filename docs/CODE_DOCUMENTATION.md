# ğŸ“š Code Documentation - Professional Development Guide

## ğŸ¯ Overview
×ª×™×¢×•×“ ××¤×•×¨×˜ ×©×œ ×›×œ ×§×•×‘×¥ ×•×§×•×‘×¥ ×‘××¢×¨×›×ª, ×›×•×œ×œ ×”×¡×‘×¨ ×¢×œ ×›×œ ×¤×•× ×§×¦×™×”, ×§×œ××¡ ×•×©×•×¨×” ×—×©×•×‘×”.

## ğŸš€ Backend Services

### ğŸ“„ `compose/chat-api/app.py`

```python
# ============================================================================
# Enterprise AI Chatbot API - Main Application
# ============================================================================
# 
# ×–×” ×”×§×•×‘×¥ ×”×¨××©×™ ×©×œ ×”-API ×©×× ×”×œ ××ª ×›×œ ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×©×œ ×”×¦'××˜×‘×•×˜.
# ×”×§×•×‘×¥ ×›×•×œ×œ:
# - FastAPI application setup
# - Database connections (Redis, MinIO, Ollama)
# - Chat endpoint ×¢× AI integration
# - Session management
# - Error handling ×•-monitoring
# ============================================================================

import os, json, time, uuid
from datetime import datetime, timezone
from typing import AsyncGenerator, List, Dict

# ============================================================================
# IMPORTS SECTION
# ============================================================================
# ×›×œ ×”-imports ××¡×•×“×¨×™× ×œ×¤×™ ×§×˜×’×•×¨×™×”:
# 1. Standard library imports
# 2. Third-party imports  
# 3. Local imports

import httpx  # Async HTTP client ×œ×ª×§×©×•×¨×ª ×¢× Ollama
import boto3  # AWS SDK ×œ××™× ×™×•/S3
import redis.asyncio as redis  # Async Redis client
from fastapi import FastAPI, HTTPException  # Web framework
from fastapi.responses import StreamingResponse  # For streaming responses

# ============================================================================
# CONFIGURATION SECTION
# ============================================================================
# ×›×œ ×”-configuration variables ×¢× default values ×•-environment variable support

REDIS_URL = os.getenv("REDIS_URL","redis://:secure_redis_password_123@redis:6379/0")
# ×”×¡×‘×¨: Redis URL ×¢× password ××•×‘× ×”. ×”×¤×•×¨××˜: redis://:password@host:port/db
# ××©××© ×œ-session management ×•-caching

OLLAMA_URL = os.getenv("OLLAMA_URL","http://ollama:11434")
# ×”×¡×‘×¨: URL ×©×œ ×©×¨×ª Ollama ×©××¨×™×¥ ××ª ×”-LLM models

OLLAMA_MODEL = os.getenv("OLLAMA_MODEL","llama3.2:3b")
# ×”×¡×‘×¨: ×”××•×“×œ ×”×¨××©×™ ×©×œ Ollama. llama3.2:3b ×”×•× ××•×“×œ ×§×˜×Ÿ ×•××”×™×¨

MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT","http://minio:9000")
# ×”×¡×‘×¨: MinIO endpoint ×œ××™× ×™×•/S3 compatible storage

MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY","admin")
# ×”×¡×‘×¨: Access key ×œ××™× ×™×•

MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY","secure_minio_password_123")
# ×”×¡×‘×¨: Secret key ×œ××™× ×™×•

S3_BUCKET = os.getenv("S3_BUCKET","chat-archive")
# ×”×¡×‘×¨: ×©× ×”-bucket ×œ××—×¡×•×Ÿ ×©×™×—×•×ª ××¨×•×›×•×ª ×˜×•×•×—

SESSION_TTL = int(os.getenv("SESSION_TTL_SECONDS","259200"))  # 3 ×™××™×
# ×”×¡×‘×¨: ×–××Ÿ ×—×™×™× ×©×œ session ×‘-Redis (×‘×©× ×™×•×ª). 259200 = 3 ×™××™×

# ============================================================================
# FASTAPI APPLICATION SETUP
# ============================================================================

app = FastAPI(title="Org Chat POC")
# ×”×¡×‘×¨: ×™×¦×™×¨×ª FastAPI application ×¢× ×©× ×¤×©×•×˜

# Global variables ×©×™×”×™×• ×–××™× ×•×ª ×‘×›×œ ×”-application
rds = None  # Redis client
s3 = None   # MinIO/S3 client

def _ts():
    """
    Helper function ×œ×”×—×–×¨×ª timestamp × ×•×›×—×™
    Returns: ISO formatted timestamp string
    """
    return datetime.now(timezone.utc).isoformat()

# ============================================================================
# STARTUP EVENT
# ============================================================================

@app.on_event("startup")
async def startup():
    """
    Event handler ×©××ª×‘×¦×¢ ×‘×¢×ª ×”×¤×¢×œ×ª ×”×©×¨×ª
    
    ×”×¤×•× ×§×¦×™×”:
    1. ××ª×—×‘×¨×ª ×œ-Redis
    2. ××ª×—×‘×¨×ª ×œ-MinIO/S3
    3. ×‘×•×“×§×ª ×©×”-bucket ×§×™×™×
    4. ××›×™× ×” ××ª ×”××¢×¨×›×ª ×œ×¢×‘×•×“×”
    """
    global rds, s3
    
    # ×”×ª×—×‘×¨×•×ª ×œ-Redis
    rds = await redis.from_url(REDIS_URL, decode_responses=True)
    
    # ×”×ª×—×‘×¨×•×ª ×œ-MinIO/S3
    s3 = boto3.client(
        "s3",
        endpoint_url=MINIO_ENDPOINT,
        aws_access_key_id=MINIO_ACCESS_KEY,
        aws_secret_access_key=MINIO_SECRET_KEY,
        region_name="us-east-1",
    )
    
    # ×•×™×“×•× ×©×”-bucket ×§×™×™×
    try:
        s3.head_bucket(Bucket=S3_BUCKET)
        # head_bucket ×‘×•×“×§ ×× ×”-bucket ×§×™×™×
    except Exception:
        # ×× ×”-bucket ×œ× ×§×™×™×, ×™×•×¦×¨×™× ××•×ª×•
        s3.create_bucket(Bucket=S3_BUCKET)

# ============================================================================
# SESSION MANAGEMENT FUNCTIONS
# ============================================================================

async def get_ctx(session_id: str) -> List[Dict]:
    """
    ×§×‘×œ×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×-Redis
    
    Args:
        session_id: ××–×”×” ×”-session
        
    Returns:
        ×¨×©×™××” ×©×œ ×”×•×“×¢×•×ª ×‘×©×™×—×”
    """
    data = await rds.get(f"sess:{session_id}")
    # ××¤×ª×— Redis: sess:session_id
    return json.loads(data) if data else []
    # ×× ×™×© × ×ª×•× ×™× - ××¤×¢× ×— JSON, ××—×¨×ª ××—×–×™×¨ ×¨×©×™××” ×¨×™×§×”

async def set_ctx(session_id: str, messages: List[Dict]):
    """
    ×©××™×¨×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×‘-Redis
    
    Args:
        session_id: ××–×”×” ×”-session
        messages: ×¨×©×™××ª ×”×•×“×¢×•×ª ×œ×©××™×¨×”
    """
    await rds.set(f"sess:{session_id}", json.dumps(messages), ex=SESSION_TTL)
    # ex=SESSION_TTL ××’×“×™×¨ ×–××Ÿ ×—×™×™× ×œ-key

# ============================================================================
# AI RESPONSE GENERATION
# ============================================================================

async def ollama_stream(ctx: List[Dict]) -> AsyncGenerator[str, None]:
    """
    ×™×¦×™×¨×ª ×ª×’×•×‘×” ×-AI ×¢× streaming
    
    Args:
        ctx: ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”
        
    Yields:
        ×—×œ×§×™× ×©×œ ×”×ª×’×•×‘×” ×‘×–××Ÿ ×××ª
    """
    # ×”×•×¡×¤×ª system message ×‘×¢×‘×¨×™×ª
    if not ctx:
        ctx = [{"role": "system", "content": """××ª×” ×¢×•×–×¨ ××¨×’×•× ×™ ×—×›× ×•××•×¢×™×œ ×‘×¢×‘×¨×™×ª.

×ª×¤×§×™×“×š:
- ×œ×¢× ×•×ª ×¢×œ ×©××œ×•×ª ×¢×¡×§×™×•×ª, ×˜×›× ×•×œ×•×’×™×•×ª ×•× ×™×”×•×œ×™×•×ª
- ×œ×ª×ª ×¢×¦×•×ª ××¢×©×™×•×ª ×•×§×•× ×§×¨×˜×™×•×ª
- ×œ×”×™×•×ª ××§×¦×•×¢×™, ×™×“×™×“×•×ª×™ ×•××•×¢×™×œ
- ×œ×¢× ×•×ª ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“
- ×œ×ª×ª ×ª×©×•×‘×•×ª ×‘×¨×•×¨×•×ª ×•×××•×§×“×•×ª
- ×œ×©××•×œ ×©××œ×•×ª ×”×‘×”×¨×” ×›×©×¦×¨×™×š

×ª××™×“ ×”×ª×—×œ ××ª ×”×ª×©×•×‘×” ×‘×‘×¨×›×” ×§×¦×¨×” ×•×ª×Ÿ ××™×“×¢ ×¨×œ×•×•× ×˜×™ ×•××¢×©×™."""}]
    
    # ×§×¨×™××” ×œ-Ollama API
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "POST",
            f"{OLLAMA_URL}/api/chat",
            json={
                "model": OLLAMA_MODEL,
                "messages": ctx,
                "stream": True,  # Streaming mode
            },
            timeout=120.0
        ) as response:
            if response.status_code != 200:
                text = await response.aread()
                raise HTTPException(500, f"ollama error: {text.decode('utf-8','ignore')}")
            
            # ×§×¨×™××ª ×”×ª×’×•×‘×” ×—×œ×§ ××—×¨ ×—×œ×§
            async for chunk in response.aiter_lines():
                if chunk.strip():
                    try:
                        data = json.loads(chunk)
                        if "message" in data and "content" in data["message"]:
                            yield data["message"]["content"]
                    except json.JSONDecodeError:
                        continue

# ============================================================================
# MAIN CHAT ENDPOINT
# ============================================================================

@app.post("/chat")
async def chat(request: dict):
    """
    Endpoint ×”×¨××©×™ ×œ×¦'××˜
    
    Args:
        request: Dictionary ×¢× prompt ×•-session_id
        
    Returns:
        StreamingResponse ×¢× ×”×ª×’×•×‘×” ×©×œ ×”-AI
    """
    # ×•×™×“×•× ×©×™×© prompt ×•-session_id
    if "prompt" not in request or "session_id" not in request:
        raise HTTPException(400, "session_id ×•-prompt ×—×•×‘×”")
    
    prompt = request["prompt"]
    session_id = request["session_id"]
    
    # ×§×‘×œ×ª ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”
    ctx = await get_ctx(session_id)
    
    # ×”×•×¡×¤×ª ×”×”×•×“×¢×” ×”×—×“×©×” ×œ×”×™×¡×˜×•×¨×™×”
    new_ctx = ctx + [{"role": "user", "content": prompt}]
    
    # ×©××™×¨×ª ×”×”×™×¡×˜×•×¨×™×” ×”××¢×•×“×›× ×ª
    await set_ctx(session_id, new_ctx)
    
    # ×™×¦×™×¨×ª response ×¢× streaming
    def gen():
        # ×™×¦×™×¨×ª generator function
        async def _gen():
            full_response = ""
            async for chunk in ollama_stream(new_ctx):
                full_response += chunk
                yield f"data: {json.dumps({'chunk': chunk})}\n\n"
            
            # ×”×•×¡×¤×ª ×”×ª×’×•×‘×” ×”××œ××” ×œ×”×™×¡×˜×•×¨×™×”
            final_ctx = new_ctx + [{"role": "assistant", "content": full_response}]
            await set_ctx(session_id, final_ctx)
            
            # ×©×œ×™×—×” ×œ-MinIO ×œ××—×¡×•×Ÿ ××¨×•×š ×˜×•×•×—
            try:
                s3.put_object(
                    Bucket=S3_BUCKET,
                    Key=f"conversations/{session_id}/{int(time.time())}.json",
                    Body=json.dumps(final_ctx),
                    ContentType="application/json"
                )
            except Exception as e:
                print(f"Failed to archive conversation: {e}")
        
        return _gen()
    
    return StreamingResponse(
        gen(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

# ============================================================================
# APPLICATION STARTUP
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    # ×”×¤×¢×œ×ª ×”×©×¨×ª ×¢×œ ×›×œ ×”-interfaces ×‘×¤×•×¨×˜ 8000
```

## ğŸ¨ Frontend Components

### ğŸ“„ `frontend/src/App.tsx`

```typescript
// ============================================================================
// React Main Application Component
// ============================================================================
// 
// ×–×” ×”×§×•××¤×•× × ×˜ ×”×¨××©×™ ×©×œ ×”××¤×œ×™×§×¦×™×”.
// ×›×•×œ×œ:
// - State management
// - Connection monitoring
// - Component coordination
// ============================================================================

import React, { useState, useEffect } from 'react';
import { ChatInterface } from './components/ChatInterface';
import { Header } from './components/Header';
import './App.css';

// ============================================================================
// INTERFACES AND TYPES
// ============================================================================

interface Message {
  id: string;
  content: string;
  timestamp: Date;
  sender: 'user' | 'ai';
  confidence?: number;
  sources?: string[];
}

// ============================================================================
// MAIN APP COMPONENT
// ============================================================================

const App: React.FC = () => {
  // ========================================================================
  // STATE MANAGEMENT
  // ========================================================================
  
  const [isConnected, setIsConnected] = useState(false);
  // ××¦×‘ ×”×—×™×‘×•×¨ ×œ×©×¨×ª - true ×× ×”×©×¨×ª ×–××™×Ÿ
  
  const [messages, setMessages] = useState<Message[]>([]);
  // ×¨×©×™××ª ×”×”×•×“×¢×•×ª ×‘×¦'××˜
  
  const [isLoading, setIsLoading] = useState(false);
  // ××¦×‘ ×˜×¢×™× ×” - true ×›×©××—×›×™× ×œ×ª×’×•×‘×” ××”×©×¨×ª
  
  // ========================================================================
  // CONNECTION MONITORING
  // ========================================================================
  
  useEffect(() => {
    /**
     * ×‘×“×™×§×ª ×—×™×‘×•×¨ ×œ×©×¨×ª ×›×œ 30 ×©× ×™×•×ª
     * 
     * ×”×¤×•× ×§×¦×™×”:
     * 1. ×©×•×œ×—×ª ×‘×§×©×” ×œ-/api/health
     * 2. ××¢×“×›× ×ª ××ª ××¦×‘ ×”×—×™×‘×•×¨
     * 3. ××’×“×™×¨×” interval ×œ×‘×“×™×§×•×ª ×—×•×–×¨×•×ª
     */
    const checkConnection = async () => {
      try {
        const response = await fetch('/api/health');
        setIsConnected(response.ok);
      } catch (error) {
        console.error('Connection check failed:', error);
        setIsConnected(false);
      }
    };

    // ×‘×“×™×§×” ×¨××©×•× ×™×ª
    checkConnection();
    
    // ×”×’×“×¨×ª interval ×œ×‘×“×™×§×•×ª ×—×•×–×¨×•×ª
    const interval = setInterval(checkConnection, 30000);
    
    // Cleanup function
    return () => clearInterval(interval);
  }, []);

  // ========================================================================
  // MESSAGE HANDLING
  // ========================================================================
  
  const handleSendMessage = async (content: string) => {
    /**
     * ×©×œ×™×—×ª ×”×•×“×¢×” ×œ×©×¨×ª
     * 
     * Args:
     *   content: ×ª×•×›×Ÿ ×”×”×•×“×¢×”
     * 
     * ×”×¤×•× ×§×¦×™×”:
     * 1. ××•×¡×™×¤×” ×”×•×“×¢×ª ××©×ª××© ×œ×¨×©×™××”
     * 2. ×©×•×œ×—×ª ×‘×§×©×” ×œ×©×¨×ª
     * 3. ××¢×‘×“×ª ××ª ×”×ª×’×•×‘×”
     * 4. ××•×¡×™×¤×” ×ª×’×•×‘×ª AI ×œ×¨×©×™××”
     */
    
    // ×”×•×¡×¤×ª ×”×•×“×¢×ª ××©×ª××©
    const userMessage: Message = {
      id: generateId(),
      content,
      timestamp: new Date(),
      sender: 'user'
    };
    
    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);

    try {
      // ×©×œ×™×—×ª ×‘×§×©×” ×œ×©×¨×ª
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          prompt: content,
          session_id: getSessionId(),
          user_id: getCurrentUserId()
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      // ×§×¨×™××ª ×”×ª×’×•×‘×”
      const data = await response.json();
      
      // ×”×•×¡×¤×ª ×ª×’×•×‘×ª AI
      const aiMessage: Message = {
        id: generateId(),
        content: data.response,
        timestamp: new Date(),
        sender: 'ai',
        confidence: data.confidence,
        sources: data.sources
      };
      
      setMessages(prev => [...prev, aiMessage]);
      
    } catch (error) {
      console.error('Failed to send message:', error);
      
      // ×”×•×¡×¤×ª ×”×•×“×¢×ª ×©×’×™××”
      const errorMessage: Message = {
        id: generateId(),
        content: '××¦×˜×¢×¨, ××™×¨×¢×” ×©×’×™××”. ×× × × ×¡×” ×©×•×‘.',
        timestamp: new Date(),
        sender: 'ai'
      };
      
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  // ========================================================================
  // HELPER FUNCTIONS
  // ========================================================================
  
  const generateId = (): string => {
    /** ×™×¦×™×¨×ª ××–×”×” ×™×™×—×•×“×™ ×œ×”×•×“×¢×” */
    return Math.random().toString(36).substr(2, 9);
  };

  const getSessionId = (): string => {
    /** ×§×‘×œ×ª ××–×”×” session × ×•×›×—×™ */
    let sessionId = localStorage.getItem('session_id');
    if (!sessionId) {
      sessionId = generateId();
      localStorage.setItem('session_id', sessionId);
    }
    return sessionId;
  };

  const getCurrentUserId = (): string => {
    /** ×§×‘×œ×ª ××–×”×” ××©×ª××© × ×•×›×—×™ */
    return localStorage.getItem('user_id') || 'anonymous';
  };

  // ========================================================================
  // RENDER
  // ========================================================================
  
  return (
    <div className="app">
      {/* Header ×¢× ××™× ×“×™×§×˜×•×¨ ×—×™×‘×•×¨ */}
      <Header isConnected={isConnected} />
      
      {/* ×××©×§ ×”×¦'××˜ ×”×¨××©×™ */}
      <ChatInterface 
        messages={messages}
        isLoading={isLoading}
        onSendMessage={handleSendMessage}
      />
    </div>
  );
};

export default App;
```

## ğŸ—„ï¸ Database Integration

### ğŸ“„ `compose/chat-api/vector_search.py`

```python
# ============================================================================
# Vector Search Service - Weaviate Integration
# ============================================================================
# 
# ×©×™×¨×•×ª ×—×™×¤×•×© ×¡×× ×˜×™ ××ª×§×“× ×¢× Weaviate
# ×›×•×œ×œ:
# - ×™×¦×™×¨×ª embeddings
# - ×—×™×¤×•×© ×“×•××”
# - ××™× ×“×•×§×¡ ××¡××›×™×
# ============================================================================

import weaviate
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Optional
import numpy as np

class VectorSearchService:
    """
    ×©×™×¨×•×ª ×—×™×¤×•×© ×¡×× ×˜×™ ×¢× Weaviate
    
    ×”×©×™×¨×•×ª ××¡×¤×§:
    - ×™×¦×™×¨×ª embeddings ××ª×•×š ×˜×§×¡×˜
    - ×—×™×¤×•×© ×“×•××” ×‘××¡×“ ×”× ×ª×•× ×™×
    - ××™× ×“×•×§×¡ ××¡××›×™× ×—×“×©×™×
    - × ×™×”×•×œ ×¡×›××ª ×”× ×ª×•× ×™×
    """
    
    def __init__(self, weaviate_url: str):
        """
        ××ª×—×•×œ ×”×©×™×¨×•×ª
        
        Args:
            weaviate_url: URL ×©×œ ×©×¨×ª Weaviate
        """
        self.client = weaviate.Client(url=weaviate_url)
        # ××ª×—×•×œ sentence transformer ×œ×™×¦×™×¨×ª embeddings
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self._initialize_schema()
    
    def _initialize_schema(self):
        """
        ××ª×—×•×œ ×¡×›××ª ×”× ×ª×•× ×™× ×‘-Weaviate
        
        ×™×•×¦×¨ class ×‘×©× "Document" ×¢× ×”×××¤×™×™× ×™×:
        - content: ×ª×•×›×Ÿ ×”××¡××š
        - title: ×›×•×ª×¨×ª ×”××¡××š
        - category: ×§×˜×’×•×¨×™×”
        - embedding: ×•×§×˜×•×¨ ×”-embedding
        """
        schema = {
            "class": "Document",
            "description": "Enterprise documents for semantic search",
            "properties": [
                {
                    "name": "content",
                    "dataType": ["text"],
                    "description": "Document content"
                },
                {
                    "name": "title", 
                    "dataType": ["string"],
                    "description": "Document title"
                },
                {
                    "name": "category",
                    "dataType": ["string"],
                    "description": "Document category"
                },
                {
                    "name": "embedding",
                    "dataType": ["number[]"],
                    "description": "Vector embedding"
                }
            ]
        }
        
        try:
            self.client.schema.create_class(schema)
        except Exception as e:
            if "already exists" not in str(e):
                raise
    
    async def index_document(self, content: str, title: str, category: str):
        """
        ××™× ×“×•×§×¡ ××¡××š ×—×“×©
        
        Args:
            content: ×ª×•×›×Ÿ ×”××¡××š
            title: ×›×•×ª×¨×ª ×”××¡××š
            category: ×§×˜×’×•×¨×™×™×ª ×”××¡××š
            
        ×”×¤×•× ×§×¦×™×”:
        1. ×™×•×¦×¨×ª embedding ××ª×•×š ×”×ª×•×›×Ÿ
        2. ×©×•××¨×ª ××ª ×”××¡××š ×‘-Weaviate
        """
        # ×™×¦×™×¨×ª embedding
        embedding = self.embedder.encode(content).tolist()
        
        # ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ ××¡××š
        document = {
            "content": content,
            "title": title,
            "category": category,
            "embedding": embedding
        }
        
        # ×©××™×¨×” ×‘-Weaviate
        self.client.data_object.create(
            data_object=document,
            class_name="Document"
        )
    
    async def search_similar(self, query: str, limit: int = 5) -> List[Dict]:
        """
        ×—×™×¤×•×© ××¡××›×™× ×“×•××™×
        
        Args:
            query: ×©××™×œ×ª×ª ×—×™×¤×•×©
            limit: ××¡×¤×¨ ×ª×•×¦××•×ª ××§×¡×™××œ×™
            
        Returns:
            ×¨×©×™××ª ××¡××›×™× ×“×•××™× ×¢× ×¦×™×•× ×™×
            
        ×”×¤×•× ×§×¦×™×”:
        1. ×™×•×¦×¨×ª embedding ××”×©××™×œ×ª×”
        2. ××—×¤×©×ª ××¡××›×™× ×“×•××™×
        3. ××—×–×™×¨×” ×ª×•×¦××•×ª ×¢× ×¦×™×•× ×™ ×“××™×•×Ÿ
        """
        # ×™×¦×™×¨×ª embedding ××”×©××™×œ×ª×”
        query_embedding = self.embedder.encode(query).tolist()
        
        # ×‘×™×¦×•×¢ ×—×™×¤×•×© ×•×§×˜×•×¨×™
        result = (
            self.client.query
            .get("Document", ["content", "title", "category"])
            .with_near_vector({"vector": query_embedding})
            .with_limit(limit)
            .with_additional(["certainty"])
            .do()
        )
        
        return result["data"]["Get"]["Document"]
```

## ğŸ”§ Configuration Files

### ğŸ“„ `docker-compose.advanced.yml`

```yaml
# ============================================================================
# Docker Compose - Advanced Enterprise Setup
# ============================================================================
# 
# ×§×•×‘×¥ Docker Compose ×œ××¢×¨×›×ª ××ª×§×“××ª ×¢×:
# - Vector Database (Weaviate)
# - Graph Database (Neo4j)
# - PostgreSQL ×¢× replication
# - Redis clustering
# - Monitoring stack
# ============================================================================

version: '3.8'

services:
  # ========================================================================
  # VECTOR DATABASE - WEAVIATE
  # ========================================================================
  weaviate:
    image: semitechnologies/weaviate:1.25.0
    restart: on-failure
    ports:
      - "8080:8080"    # HTTP API
      - "50051:50051"  # gRPC API
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'  # × ×©×ª××© ×‘-embeddings ×©×œ× ×•
      ENABLE_MODULES: 'text2vec-transformers'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    networks:
      - chatnet
    # ×”×¡×‘×¨: Weaviate ×”×•× vector database ××ª×§×“× ×œ×—×™×¤×•×© ×¡×× ×˜×™

  # ========================================================================
  # GRAPH DATABASE - NEO4J
  # ========================================================================
  neo4j:
    image: neo4j:5.19.0-community
    restart: on-failure
    ports:
      - "7474:7474"  # HTTP interface
      - "7687:7687"  # Bolt protocol
    environment:
      NEO4J_AUTH: neo4j/secure_neo4j_password_123
      NEO4J_db_fsync__metadata: "false"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - chatnet
    # ×”×¡×‘×¨: Neo4j ×”×•× graph database ×œ×§×©×¨×™× ××•×¨×›×‘×™×

  # ========================================================================
  # POSTGRESQL DATABASE
  # ========================================================================
  postgres:
    image: postgres:15-alpine
    restart: on-failure
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-org_chatbot}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_postgres_password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - chatnet
    # ×”×¡×‘×¨: PostgreSQL ×”×•× ×”-database ×”×¨××©×™

  # ========================================================================
  # REDIS CACHE
  # ========================================================================
  redis:
    image: redis:7-alpine
    restart: on-failure
    ports:
      - "6379:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-secure_redis_password_123}
    volumes:
      - redis_data:/data
    networks:
      - chatnet
    # ×”×¡×‘×¨: Redis ×œ-session management ×•-caching

  # ========================================================================
  # AI/LLM SERVICE - OLLAMA
  # ========================================================================
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - chatnet
    entrypoint: ["/bin/sh","-lc","ollama serve & sleep 5 && ollama pull ${OLLAMA_MODEL:-llama3.2:3b} && ollama pull ${OLLAMA_FAST_MODEL:-phi3:3.8b} && wait"]
    # ×”×¡×‘×¨: Ollama ××¨×™×¥ LLM models ××§×•××™×ª

  # ========================================================================
  # CHAT API SERVICE
  # ========================================================================
  chat-api:
    build:
      context: ./chat-api
      dockerfile: Dockerfile.advanced
    restart: unless-stopped
    depends_on:
      - redis
      - minio
      - ollama
      - weaviate
      - neo4j
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD:-secure_redis_password_123}@redis:6379/0
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-admin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-secure_minio_password_123}
      S3_BUCKET: ${S3_BUCKET:-chat-archive}
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      OLLAMA_FAST_MODEL: ${OLLAMA_FAST_MODEL:-phi3:3.8b}
      SESSION_TTL_SECONDS: ${SESSION_TTL_SECONDS:-259200}
      WEAVIATE_URL: http://weaviate:8080
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: secure_neo4j_password_123
    ports:
      - "8000:8000"
    networks:
      - chatnet
    # ×”×¡×‘×¨: ×”×©×™×¨×•×ª ×”×¨××©×™ ×©××—×‘×¨ ×‘×™×Ÿ ×›×œ ×”×¨×›×™×‘×™×

# ========================================================================
# VOLUMES
# ========================================================================
volumes:
  weaviate_data:
  neo4j_data:
  neo4j_logs:
  postgres_data:
  redis_data:
  ollama_data:
  minio_data:
  # ×”×¡×‘×¨: Volumes ×œ××—×¡×•×Ÿ × ×ª×•× ×™× ××ª××™×“

# ========================================================================
# NETWORKS
# ========================================================================
networks:
  chatnet:
    driver: bridge
    # ×”×¡×‘×¨: ×¨×©×ª ×¤× ×™××™×ª ×œ×›×œ ×”×©×™×¨×•×ª×™×
```

---

**×ª×™×¢×•×“ ×–×” ××¡×¤×§ ×”×¡×‘×¨ ××¤×•×¨×˜ ×¢×œ ×›×œ ×—×œ×§ ×‘××¢×¨×›×ª, ×›×•×œ×œ ××˜×¨×•×ª, ×¤×•× ×§×¦×™×•× ×œ×™×•×ª, ×•×¤×¨×˜×™× ×˜×›× ×™×™×.**
