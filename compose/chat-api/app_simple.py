import os
import json
import time
import uuid
from datetime import datetime, timezone
from typing import AsyncGenerator, List, Dict

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Simple Org Chat API")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# In-memory storage for demo
sessions = {}

def _ts():
    return datetime.now(timezone.utc).isoformat()

def get_mock_response(user_prompt: str) -> str:
    """Generate a mock intelligent response in Hebrew"""
    
    # Simple keyword-based responses
    prompt_lower = user_prompt.lower()
    
    if any(word in prompt_lower for word in ['爪专', '驻转', '砖']):
        return """砖!  砖 注专 驻转 爪专 砖. 

 转 抓:
1. **拽专 砖拽** - 拽 转 爪专 砖 拽转
2. **驻 爪专** - 专 转 转转 注拽专转
3. ** 驻住** - 爪专 专住 专砖转 拽
4. **拽转 砖拽** - 拽 驻拽 拽转
5. **砖驻专** - 转拽 注转 砖 转转

 转专爪 砖注拽  砖?"""

    elif any(word in prompt_lower for word in ['砖拽', '', '拽驻']):
        return """砖! 拽驻 砖拽   专 爪转 注 拽转.

**住专 爪转:**
1. **专转 注** -  转 专爪 砖?
2. ** 拽 注** -  拽转 砖?
3. **专转 注专爪** - 驻住拽, , 住专?
4. **转 转** - 爪专 转 专 注
5. ** 注拽** - 注拽 专 转爪转

 注专抓 砖拽 注 转  专?"""

    elif any(word in prompt_lower for word in ['爪转', '', '注']):
        return """砖!  爪转 注  驻转 爪 注住拽转.

**注拽专转 砖:**
1. **转拽砖专转 专专** - 专 爪驻转 转驻拽
2. **爪转 住转** - 转 爪转 专转
3. **驻拽 拽注** - 拽 转拽转 驻 拽注
4. **专 拽专** - 注专 转 注 
5. **驻转 砖** - 砖拽注 砖专 转驻转转

 转 专 转 转专   爪转?"""

    elif any(word in prompt_lower for word in ['', '转转', 'ai', '']):
        return """砖!  转转  砖转 转 注住拽 砖 !

**砖砖 注住拽:**
1. **爪** - 砖转 专转 驻砖转
2. **转 转** - 转 拽转 砖拽
3. **砖专转 拽转** - 爪' 注专 24/7
4. **转** - 爪专转 拽住 转转
5. **** - 转转 专转 转

 转 注住拽 砖  注 转 砖驻专 注 AI?"""

    else:
        return f"""砖!  注专 专  砖.

  注专  注:
-  驻转 爪专 砖专转
-  住专转 砖拽 注住拽
-   爪转 驻专拽
-    转转
-  转 转 转转

砖 砖: "{user_prompt}"

   注专  驻 住驻爪驻 转专? 住 砖 注  转   住驻专  转专 注 转专 砖."""

async def mock_stream_response(response_text: str) -> AsyncGenerator[str, None]:
    """Simulate streaming response by sending chunks"""
    words = response_text.split(' ')
    for i, word in enumerate(words):
        yield word + (' ' if i < len(words) - 1 else '')
        # Small delay to simulate real streaming
        await asyncio.sleep(0.05)

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "Simple Chat API",
        "timestamp": _ts()
    }

@app.post("/chat")
async def chat(body: Dict):
    session_id = (body.get("session_id") or "").strip()
    prompt = (body.get("prompt") or "").strip()
    
    if not session_id or not prompt:
        raise HTTPException(400, "session_id -prompt ")

    # Get or create session
    if session_id not in sessions:
        sessions[session_id] = []
    
    # Store user message
    user_message = {
        "id": f"user_{int(time.time())}",
        "role": "user", 
        "content": prompt,
        "timestamp": _ts()
    }
    sessions[session_id].append(user_message)

    # Generate response
    response_text = get_mock_response(prompt)
    
    # Store assistant message
    assistant_message = {
        "id": f"assistant_{int(time.time())}",
        "role": "assistant",
        "content": response_text,
        "timestamp": _ts()
    }
    sessions[session_id].append(assistant_message)

    async def generate_response():
        async for chunk in mock_stream_response(response_text):
            yield chunk

    return StreamingResponse(
        generate_response(),
        media_type="text/plain; charset=utf-8"
    )

@app.get("/sessions/{session_id}")
async def get_session(session_id: str):
    if session_id not in sessions:
        return {"session_id": session_id, "messages": []}
    
    return {
        "session_id": session_id,
        "messages": sessions[session_id]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
